server:
  port: 8080
  servlet:
    context-path: /identity
jwt:
  signKey: "OB0RdAPKk205HmONdsjs/FV8oLzmu9i+ObfyWB/CvazOJbpXAtXuUszLnxQTRd4P"
  valid-duration: 3600 #in second
  refreshable-duration: 360000 #in second

spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/test?useUnicode=true&characterEncoding=utf8&useSSL=false
    username: root
    password: ${DBMS_PASSWORD:123456}
    hikari:
      data-source-properties:
        cachePrepStmts: true
        prepStmtCacheSqlLimit: 2048
        useServerPrepStmts: true
  jpa:
    hibernate:
      ddl-auto: update
      use-new-id-generator-mapping: false
    database-platform: org.hibernate.dialect.MySQL8Dialect
    database: MYSQL
    show-sql: true
    properties:
      hibernate.cache.use_second_level_cache: false
      hibernate.cache.use_query_cache: false
      hibernate.generate_statistics: true
      hibernate.cache.region.factory_class: org.hibernate.cache.ehcache.SingletonEhCacheRegionFactory
    open-in-view: false
  config:
    active:
      on-profile: dev # this mean, when Packing the application into a jar that will use this file
  kafka: # must install kafka with docker, can implement this configuration
    # port was be config at docker-compose.yml file, this port same with docker-compose.yml file
    bootstrap-servers: localhost:9094 # this mean kafka is listening on localhost 9094 of kafka broker
    producer:
      # sent message is String can set up by us
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer # this mean sent message is string to notification service
#      refreshable-serializer: org.apache.kafka.common.serialization.StringSerializer
      # or sent message is object we can using config below
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer # this means sent data not is String, that sent an object
      # properties is when want to sent to each other, is have attribute contain data is UserResponse,
      properties:  # "user:" is name of attribute have data is UserResponse
        "[spring.json.type.mapping]": user:com.example.identity.dto.response.UserResponse  # when have many attributes, copy properties through below, this case processing : 1 topic will be many type messages , and consumer will consume these massages
    consumer:
      group-id: identity-group
      auto-offset-reset: earliest
      value-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer # then sent data according to "Serializer", we listen "deserializer" to change th√†nh object of java that producer push to kafka broker

app:
  service:
    profile: http://localhost:4567/profile
logging:
  config: classpath:audit-logback-spring.xml
#  level:
#    root: INFO
#  file:
#    config: classpath:file-logback-spring.xml
#    path: C:/Users/user/Downloads/demo/demo/FileLogApp/gateway-client.log
#    max-history: 365
#    max-file-size: 100MB
#    pattern: '%d{yyyy-MM-dd HH:mm:sss.SSS} [%thread] - [%-5level] [%logger{50} :%line] - %msg%n'
